{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOw0egtwbHq5Afl0CaQmEls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavb/ai-tests/blob/main/HelloWorld_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiAkWIGxo3R9",
        "outputId": "d70960ab-e083-4aa8-f531-5923d4793e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n",
            "False\n",
            "<function version at 0x7b6c84a272e0>\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.backends.cudnn.version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWFtgUX85iwO"
      },
      "source": [
        "## our data in tensor form\n",
        "x = torch.tensor([[-1.0],  [0.0], [1.0], [2.0], [3.0], [4.0]], dtype=torch.float)\n",
        "y = torch.tensor([[-3.0], [-1.0], [1.0], [3.0], [5.0], [7.0]], dtype=torch.float)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.size()\n",
        "y.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM2rvC0Xpx8F",
        "outputId": "d72b8d39-c377-4f5a-af52-6ac8f77481c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1Ii5JRz3Jud"
      },
      "source": [
        "## Neural network with 1 hidden layer\n",
        "layer1 = nn.Linear(1,1, bias=False)\n",
        "model = nn.Sequential(layer1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hglFpejArxx"
      },
      "source": [
        "## loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "## optimizer algorithm\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeOr9i-aBzRv",
        "outputId": "599fc269-a760-4977-bf99-ed1d369f17cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## training\n",
        "for ITER in range(150):\n",
        "    model = model.train()\n",
        "\n",
        "    ## forward\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    ## backward + update model params\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    print('Epoch: %d | Loss: %.4f' %(ITER, loss.detach().item()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 26.7018\n",
            "Epoch: 1 | Loss: 21.5792\n",
            "Epoch: 2 | Loss: 17.4605\n",
            "Epoch: 3 | Loss: 14.1491\n",
            "Epoch: 4 | Loss: 11.4867\n",
            "Epoch: 5 | Loss: 9.3461\n",
            "Epoch: 6 | Loss: 7.6250\n",
            "Epoch: 7 | Loss: 6.2412\n",
            "Epoch: 8 | Loss: 5.1286\n",
            "Epoch: 9 | Loss: 4.2341\n",
            "Epoch: 10 | Loss: 3.5149\n",
            "Epoch: 11 | Loss: 2.9367\n",
            "Epoch: 12 | Loss: 2.4718\n",
            "Epoch: 13 | Loss: 2.0980\n",
            "Epoch: 14 | Loss: 1.7974\n",
            "Epoch: 15 | Loss: 1.5558\n",
            "Epoch: 16 | Loss: 1.3615\n",
            "Epoch: 17 | Loss: 1.2053\n",
            "Epoch: 18 | Loss: 1.0797\n",
            "Epoch: 19 | Loss: 0.9787\n",
            "Epoch: 20 | Loss: 0.8976\n",
            "Epoch: 21 | Loss: 0.8323\n",
            "Epoch: 22 | Loss: 0.7798\n",
            "Epoch: 23 | Loss: 0.7376\n",
            "Epoch: 24 | Loss: 0.7037\n",
            "Epoch: 25 | Loss: 0.6764\n",
            "Epoch: 26 | Loss: 0.6545\n",
            "Epoch: 27 | Loss: 0.6368\n",
            "Epoch: 28 | Loss: 0.6227\n",
            "Epoch: 29 | Loss: 0.6113\n",
            "Epoch: 30 | Loss: 0.6021\n",
            "Epoch: 31 | Loss: 0.5947\n",
            "Epoch: 32 | Loss: 0.5888\n",
            "Epoch: 33 | Loss: 0.5841\n",
            "Epoch: 34 | Loss: 0.5802\n",
            "Epoch: 35 | Loss: 0.5771\n",
            "Epoch: 36 | Loss: 0.5747\n",
            "Epoch: 37 | Loss: 0.5727\n",
            "Epoch: 38 | Loss: 0.5711\n",
            "Epoch: 39 | Loss: 0.5698\n",
            "Epoch: 40 | Loss: 0.5688\n",
            "Epoch: 41 | Loss: 0.5679\n",
            "Epoch: 42 | Loss: 0.5673\n",
            "Epoch: 43 | Loss: 0.5667\n",
            "Epoch: 44 | Loss: 0.5663\n",
            "Epoch: 45 | Loss: 0.5659\n",
            "Epoch: 46 | Loss: 0.5657\n",
            "Epoch: 47 | Loss: 0.5654\n",
            "Epoch: 48 | Loss: 0.5653\n",
            "Epoch: 49 | Loss: 0.5651\n",
            "Epoch: 50 | Loss: 0.5650\n",
            "Epoch: 51 | Loss: 0.5649\n",
            "Epoch: 52 | Loss: 0.5648\n",
            "Epoch: 53 | Loss: 0.5648\n",
            "Epoch: 54 | Loss: 0.5647\n",
            "Epoch: 55 | Loss: 0.5647\n",
            "Epoch: 56 | Loss: 0.5646\n",
            "Epoch: 57 | Loss: 0.5646\n",
            "Epoch: 58 | Loss: 0.5646\n",
            "Epoch: 59 | Loss: 0.5646\n",
            "Epoch: 60 | Loss: 0.5646\n",
            "Epoch: 61 | Loss: 0.5646\n",
            "Epoch: 62 | Loss: 0.5646\n",
            "Epoch: 63 | Loss: 0.5645\n",
            "Epoch: 64 | Loss: 0.5645\n",
            "Epoch: 65 | Loss: 0.5645\n",
            "Epoch: 66 | Loss: 0.5645\n",
            "Epoch: 67 | Loss: 0.5645\n",
            "Epoch: 68 | Loss: 0.5645\n",
            "Epoch: 69 | Loss: 0.5645\n",
            "Epoch: 70 | Loss: 0.5645\n",
            "Epoch: 71 | Loss: 0.5645\n",
            "Epoch: 72 | Loss: 0.5645\n",
            "Epoch: 73 | Loss: 0.5645\n",
            "Epoch: 74 | Loss: 0.5645\n",
            "Epoch: 75 | Loss: 0.5645\n",
            "Epoch: 76 | Loss: 0.5645\n",
            "Epoch: 77 | Loss: 0.5645\n",
            "Epoch: 78 | Loss: 0.5645\n",
            "Epoch: 79 | Loss: 0.5645\n",
            "Epoch: 80 | Loss: 0.5645\n",
            "Epoch: 81 | Loss: 0.5645\n",
            "Epoch: 82 | Loss: 0.5645\n",
            "Epoch: 83 | Loss: 0.5645\n",
            "Epoch: 84 | Loss: 0.5645\n",
            "Epoch: 85 | Loss: 0.5645\n",
            "Epoch: 86 | Loss: 0.5645\n",
            "Epoch: 87 | Loss: 0.5645\n",
            "Epoch: 88 | Loss: 0.5645\n",
            "Epoch: 89 | Loss: 0.5645\n",
            "Epoch: 90 | Loss: 0.5645\n",
            "Epoch: 91 | Loss: 0.5645\n",
            "Epoch: 92 | Loss: 0.5645\n",
            "Epoch: 93 | Loss: 0.5645\n",
            "Epoch: 94 | Loss: 0.5645\n",
            "Epoch: 95 | Loss: 0.5645\n",
            "Epoch: 96 | Loss: 0.5645\n",
            "Epoch: 97 | Loss: 0.5645\n",
            "Epoch: 98 | Loss: 0.5645\n",
            "Epoch: 99 | Loss: 0.5645\n",
            "Epoch: 100 | Loss: 0.5645\n",
            "Epoch: 101 | Loss: 0.5645\n",
            "Epoch: 102 | Loss: 0.5645\n",
            "Epoch: 103 | Loss: 0.5645\n",
            "Epoch: 104 | Loss: 0.5645\n",
            "Epoch: 105 | Loss: 0.5645\n",
            "Epoch: 106 | Loss: 0.5645\n",
            "Epoch: 107 | Loss: 0.5645\n",
            "Epoch: 108 | Loss: 0.5645\n",
            "Epoch: 109 | Loss: 0.5645\n",
            "Epoch: 110 | Loss: 0.5645\n",
            "Epoch: 111 | Loss: 0.5645\n",
            "Epoch: 112 | Loss: 0.5645\n",
            "Epoch: 113 | Loss: 0.5645\n",
            "Epoch: 114 | Loss: 0.5645\n",
            "Epoch: 115 | Loss: 0.5645\n",
            "Epoch: 116 | Loss: 0.5645\n",
            "Epoch: 117 | Loss: 0.5645\n",
            "Epoch: 118 | Loss: 0.5645\n",
            "Epoch: 119 | Loss: 0.5645\n",
            "Epoch: 120 | Loss: 0.5645\n",
            "Epoch: 121 | Loss: 0.5645\n",
            "Epoch: 122 | Loss: 0.5645\n",
            "Epoch: 123 | Loss: 0.5645\n",
            "Epoch: 124 | Loss: 0.5645\n",
            "Epoch: 125 | Loss: 0.5645\n",
            "Epoch: 126 | Loss: 0.5645\n",
            "Epoch: 127 | Loss: 0.5645\n",
            "Epoch: 128 | Loss: 0.5645\n",
            "Epoch: 129 | Loss: 0.5645\n",
            "Epoch: 130 | Loss: 0.5645\n",
            "Epoch: 131 | Loss: 0.5645\n",
            "Epoch: 132 | Loss: 0.5645\n",
            "Epoch: 133 | Loss: 0.5645\n",
            "Epoch: 134 | Loss: 0.5645\n",
            "Epoch: 135 | Loss: 0.5645\n",
            "Epoch: 136 | Loss: 0.5645\n",
            "Epoch: 137 | Loss: 0.5645\n",
            "Epoch: 138 | Loss: 0.5645\n",
            "Epoch: 139 | Loss: 0.5645\n",
            "Epoch: 140 | Loss: 0.5645\n",
            "Epoch: 141 | Loss: 0.5645\n",
            "Epoch: 142 | Loss: 0.5645\n",
            "Epoch: 143 | Loss: 0.5645\n",
            "Epoch: 144 | Loss: 0.5645\n",
            "Epoch: 145 | Loss: 0.5645\n",
            "Epoch: 146 | Loss: 0.5645\n",
            "Epoch: 147 | Loss: 0.5645\n",
            "Epoch: 148 | Loss: 0.5645\n",
            "Epoch: 149 | Loss: 0.5645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1odfZpGFoBi",
        "outputId": "c99c4d94-372f-4fd7-9adb-17c318c4c72b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## test the model\n",
        "sample = torch.tensor([10.0], dtype=torch.float)\n",
        "predicted = model(sample)\n",
        "print(predicted.detach().item())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.096769332885742\n"
          ]
        }
      ]
    }
  ]
}